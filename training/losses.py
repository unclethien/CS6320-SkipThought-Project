import torch
import torch.nn.functional as F
from torch import autograd

def compute_gradient_penalty(critic: torch.nn.Module, real_samples: torch.Tensor, fake_samples: torch.Tensor, conditioning_input: torch.Tensor = None) -> torch.Tensor:
    """Calculates the gradient penalty loss for WGAN-GP.

    Penalizes the norm of gradients of the critic with respect to interpolated samples.

    Args:
        critic: The critic/discriminator network.
        real_samples: Tensor of real samples (e.g., target paraphrase embeddings).
        fake_samples: Tensor of fake samples generated by the generator.
        conditioning_input: Optional conditioning input (e.g., encoded source sentence)
                            passed to the critic along with samples.

    Returns:
        Gradient penalty loss (scalar tensor).
    """
    device = real_samples.device
    batch_size = real_samples.size(0)

    # Generate random interpolation factor alpha for each sample
    alpha = torch.rand(batch_size, *([1] * (real_samples.dim() - 1)), device=device)
    # alpha shape will broadcast correctly: e.g., [batch_size, 1, 1] for images
    # or [batch_size, 1] for flat embeddings.

    # Create interpolated samples
    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)

    # Get critic scores for the interpolates
    # Adjust critic call based on whether it takes conditioning input
    if conditioning_input is not None:
        # Assume critic takes (conditioning, sample) as input
        # Ensure conditioning input is broadcastable or matches batch size
        critic_interpolates, _, _ = critic(conditioning_input, interpolates) # Ignore Q outputs if any
    else:
        # Assume critic takes only the sample as input
        critic_interpolates, _, _ = critic(interpolates) # Ignore Q outputs if any

    # Use autograd to compute gradients of scores w.r.t. interpolates
    # We need a dummy tensor of ones for the gradients argument of autograd.grad
    gradients = autograd.grad(
        outputs=critic_interpolates,
        inputs=interpolates,
        grad_outputs=torch.ones_like(critic_interpolates, requires_grad=False),
        create_graph=True,       # Create graph for second derivatives if needed (e.g. DDPG)
        retain_graph=True,       # Retain graph as this is part of a larger computation
        only_inputs=True,
    )[0]

    # Reshape gradients to [batch_size, -1] to compute norm easily
    gradients = gradients.view(batch_size, -1)

    # Calculate the L2 norm of gradients for each sample
    # Add small epsilon for numerical stability before sqrt
    gradient_norm = torch.sqrt(torch.sum(gradients**2, dim=1) + 1e-12)

    # Compute the gradient penalty: mean of (gradient_norm - 1)^2
    gradient_penalty = ((gradient_norm - 1) ** 2).mean()

    return gradient_penalty

def infogan_loss(q_disc_logits: torch.Tensor, true_disc_code: torch.Tensor, q_cont_mu: torch.Tensor, true_cont_code: torch.Tensor) -> torch.Tensor:
    """Computes the InfoGAN loss for the Q-network.

    This loss encourages mutual information between latent codes and generator output.
    It consists of a cross-entropy loss for discrete codes and an MSE loss
    (or Gaussian NLL) for continuous codes.

    Args:
        q_disc_logits: Predicted logits for the discrete latent code categories
                       (output of Q-network head). Shape: [batch_size, disc_code_dim].
        true_disc_code: Ground truth discrete latent code (indices or labels).
                        Shape: [batch_size].
        q_cont_mu: Predicted mean for the continuous latent code (output of Q-network head).
                   Shape: [batch_size, cont_code_dim].
        true_cont_code: Ground truth continuous latent code.
                        Shape: [batch_size, cont_code_dim].

    Returns:
        Combined InfoGAN Q loss (scalar tensor).
    """
    # Discrete code loss: Cross-Entropy
    # Assumes true_disc_code contains class indices (0, 1, ..., C-1)
    disc_loss = F.cross_entropy(q_disc_logits, true_disc_code)

    # Continuous code loss:
    # Option 1: Mean Squared Error (simpler, as used in the report example)
    cont_loss = F.mse_loss(q_cont_mu, true_cont_code)

    # Option 2: Gaussian Negative Log-Likelihood (more principled if Q also predicts variance)
    # If Q network also predicted log variance (q_cont_logvar):
    # q_cont_var = torch.exp(q_cont_logvar)
    # cont_loss = F.gaussian_nll_loss(q_cont_mu, true_cont_code, q_cont_var, reduction='mean')
    # We'll stick to MSE based on the report's implementation sketch.

    # Total Q loss (could add weighting factors here if needed)
    # For simplicity, sum them directly.
    # Often, a small weight (e.g., 0.1) is applied to the continuous loss.
    total_q_loss = disc_loss + 0.1 * cont_loss # Example weighting

    return total_q_loss

# Note: KL Divergence loss calculation is often included directly in the VAEEncoder model class
# or computed in the main training loop using the mu and logvar from the encoder.
# WGAN-GP critic loss: D_loss = fake_score.mean() - real_score.mean() + lambda_gp * gp
# WGAN-GP generator loss: G_loss_adv = -fake_score.mean()
# These are typically computed directly in the trainer script.
